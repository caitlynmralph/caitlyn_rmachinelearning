---
title: "Chapter 8 Exercises"
author: "Caitlyn Ralph"
date: "4/18/2018"
output_dir: "."
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Conceptual Exercise

## 3. Consider the Gini index, classification error, and cross-entropy in a simple classification setting with two classes. Create a single plot that displays each of these quantities as a function of pˆm1. The x-axis should display pˆm1, ranging from 0 to 1, and the y-axis should display the value of the Gini index, classification error, and entropy.
Hint: In a setting with two classes, pˆm1 = 1 − pˆm2. You could make this plot by hand, but it will be much easier to make in R.

```{r}
#First, I'm going to model the x-axis, plugging in five values for p^m1.
x <- c(1,2,3,4,5)

#The classification error rate is the fraction of training observations in that region that no dont belong to the most common class.
ce <- c(4/5,3/5,2/5,1/5,0)

#The Gini Index measures total variance across the K classes.
gini <- c(0.32,0.48,0.48,0.32,0)

#Cross-entropy
cross <- c(0.500,0.673,0.673,0.500,0)

#The results seem to make sense because the Gini index and cross-entropy are quite similar.

plot(x, ce)
points(gini, col="red")
points(cross, col="blue")
```

# Applied Exercise

## 10. We now use boosting to predict Salary in the Hitters data set.

### (a) Remove the observations for whom the salary information is unknown, and then log-transform the salaries.

```{r}
library(ISLR)
library(pls)
attach(Hitters)
Hitters <- na.omit(Hitters)
Hitters$Salary <- log(Hitters$Salary)
```

### (b) Create a training set consisting of the first 200 observations, and a test set consisting of the remaining observations.

```{r}
train <- seq(1,200,1)
test <- seq(201,263,1)
Hitters.train <- Hitters[train,]
Hitters.test <- Hitters[test,]
Salary.test <- Salary[test]
```

### (c) Perform boosting on the training set with 1,000 trees for a range of values of the shrinkage parameter λ. Produce a plot with different shrinkage values on the x-axis and the corresponding training set MSE on the y-axis.

```{r}
library(gbm)
shrinkage <- c(0.001, 0.02, 0.5)
training_mse <- vector()

for (i in 1:3) {
  boost.Hitters<-gbm(Salary~., data=Hitters,n.trees=1000,interaction.depth=4,shrinkage=shrinkage[i],verbose=F)
  training_mse <- c(training_mse,mean(boost.Hitters$train.error))
}
training_mse

plot(shrinkage, training_mse)
```

### (d) Produce a plot with different shrinkage values on the x-axis and the corresponding test set MSE on the y-axis.

```{r}
shrinkage <- c(0.001, 0.02, 0.5)

boost.Hitters<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=0.001)
yhat.boost<-predict(boost.Hitters,newdata=Hitters.test, n.trees=1000)
test_mse1 <- mean((yhat.boost-Salary.test)^2)

boost.Hitters<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=0.02)
yhat.boost<-predict(boost.Hitters,newdata=Hitters.test, n.trees=1000)
test_mse2 <- mean((yhat.boost-Salary.test)^2)

boost.Hitters<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=0.5)
yhat.boost<-predict(boost.Hitters,newdata=Hitters.test, n.trees=1000)
test_mse3 <- mean((yhat.boost-Salary.test)^2)

testm <- c(test_mse1, test_mse2, test_mse3)

testm
```

For some reason, no matter what format I put it in, the test MSE is coming up as NA as I Knit, even though it's coming up fine when I run the code block in R Studio. I feel like I may be losing my mind...?

### (e) Compare the test MSE of boosting to the test MSE that results from applying two of the regression approaches seen in Chapters 3 and 6.

First, a simple linear regression from Chapter 3.

```{r}
lm.hitters <- lm(Salary~., data=Hitters.train)
pred.hitters <- predict(lm.hitters, newdata=Hitters.test)
(mean(pred.hitters-Salary.test)^2)
```

Now, the ridge regression from Chapter 6.

```{r}
x<-model.matrix(Salary~.,Hitters)[,-1]
y<-Hitters$Salary
```
```{r}
library(glmnet)
grid=10^seq(10,-2,length=100)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)

set.seed(1)
cv.out <- cv.glmnet(x[train,],y[train],alpha=0)
plot(cv.out)
bestlam <- cv.out$lambda.min
bestlam
```
```{r}
ridge.pred <- predict(ridge.mod,s=bestlam,newx=x[test,])
mean((ridge.pred-Salary.test)^2)
```
The boosting model had a much lower test MSE than these two regression models.

### (f) Which variables appear to be the most important predictors in the boosted model?

```{r}
summary(boost.Hitters)
```

Judging from the above plot, it seems Walks has the most influence, but Errors, Years, and NewLeague are also important influencers.

### (g) Now apply bagging to the training set. What is the test set MSE for this approach?

```{r}
library(randomForest)
set.seed(1)
bag.Hitters<-randomForest(Salary~.,data=Hitters,subset=train,mtry=13,importance =TRUE)
yhat.bag = predict(bag.Hitters ,newdata=Hitters.test)
mean((yhat.bag-Salary.test)^2)
```
This appears to perform similar as ridge regression and the simple linear model.