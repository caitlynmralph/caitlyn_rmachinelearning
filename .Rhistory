test_mse <- c(test_mse,mean(yhat.boost-Salary.test)^2)
}
test_mse
plot(shrinkage, test_mse)
library(gbm)
shrinkage <- c(0.001, 0.02, 0.5)
test_mse <- vector()
for (i in 1:3) {
boost.Hitters1<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=shrinkage[i],verbose=F)
yhat.boost<-predict(boost.Hitters1,newdata=Hitters.test, n.trees=1000)
test_mse <- c(test_mse,mean(yhat.boost-Salary.test)^2)
}
test_mse
plot(shrinkage, test_mse)
test_mse <- vector()
for (i in 1:3) {
boost.Hitters1<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=shrinkage[i],verbose=F)
yhat.boost<-predict(boost.Hitters1,newdata=Hitters.test, n.trees=1000)
test_mse <- c(test_mse,mean(yhat.boost-Salary.test)^2)
}
test_mse
plot(shrinkage, test_mse)
test_mse <- vector()
for (x in 1:3) {
boost.Hitters1<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=shrinkage[x],verbose=F)
yhat.boost<-predict(boost.Hitters1,newdata=Hitters.test, n.trees=1000)
test_mse <- c(test_mse,mean(yhat.boost-Salary.test)^2)
}
test_mse
plot(shrinkage, test_mse)
test_mse <- vector()
for (x in 1:3) {
boost.Hitters1<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=shrinkage[x],verbose=F)
yhat.boost<-predict(boost.Hitters1,newdata=Hitters.test, n.trees=1000)
test_mse <- c(test_mse,mean(yhat.boost-Salary.test))
}
test_mse
plot(shrinkage, test_mse)
test_mse <- vector()
for (x in 1:3) {
boost.Hitters1<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=shrinkage[x])
yhat.boost<-predict(boost.Hitters1,newdata=Hitters.test, n.trees=1000)
test_mse <- c(test_mse,mean(yhat.boost-Salary.test))
}
test_mse
plot(shrinkage, test_mse)
test_mse <- vector()
for (x in 1:3) {
boost.Hitters1<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=shrinkage[x])
yhat.boost<-predict(boost.Hitters1,newdata=Hitters.test, n.trees=1000)
test_mse <- c(test_mse,mean(yhat.boost-Salary.test)^2)
}
test_mse
plot(shrinkage, test_mse)
test_mse <- vector()
for (x in 1:3) {
boost.Hitters1<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=shrinkage[x])
yhat.boost<-predict(boost.Hitters1,newdata=Hitters.test, n.trees=1000)
test_mse <- c(test_mse,mean((yhat.boost-Salary.test)^2))
}
test_mse
plot(shrinkage, test_mse)
shrinkage <- c(0.001, 0.02, 0.5)
test_mse <- vector()
for (x in 1:3) {
boost.Hitters1<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=shrinkage[x])
yhat.boost<-predict(boost.Hitters1,newdata=Hitters.test, n.trees=1000)
test_mse <- c(test_mse,mean((yhat.boost-Salary.test)^2))
}
test_mse[1]
test_mse[2]
test_mse[3]
plot(shrinkage, test_mse)
shrinkage <- c(0.001, 0.02, 0.5)
test_mse <- vector()
for (x in 1:3) {
boost.Hitters<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=shrinkage[x])
yhat.boost<-predict(boost.Hitters,newdata=Hitters.test, n.trees=1000)
test_mse <- c(test_mse,mean((yhat.boost-Salary.test)^2))
}
test_mse
shrinkage <- c(0.001, 0.02, 0.5)
test_mse <- vector()
for (x in 1:3) {
boost.Hitters<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=shrinkage[x])
yhat.boost<-predict(boost.Hitters,newdata=Hitters.test, n.trees=1000)
test_mse[x] <- mean((yhat.boost-Salary.test)^2)
}
test_mse
shrinkage <- c(0.001, 0.02, 0.5)
boost.Hitters<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=0.001)
yhat.boost<-predict(boost.Hitters,newdata=Hitters.test, n.trees=1000)
test_mse1 <- mean((yhat.boost-Salary.test)^2)
boost.Hitters<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=0.02)
yhat.boost<-predict(boost.Hitters,newdata=Hitters.test, n.trees=1000)
test_mse2 <- mean((yhat.boost-Salary.test)^2)
boost.Hitters<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=0.5)
yhat.boost<-predict(boost.Hitters,newdata=Hitters.test, n.trees=1000)
test_mse3 <- mean((yhat.boost-Salary.test)^2)
test_mse <- c(test_mse1, test_mse2, test_mse3)
test_mse
shrinkage <- c(0.001, 0.02, 0.5)
boost.Hitters<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=0.001)
yhat.boost<-predict(boost.Hitters,newdata=Hitters.test, n.trees=1000)
test_mse1 <- mean((yhat.boost-Salary.test)^2)
boost.Hitters<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=0.02)
yhat.boost<-predict(boost.Hitters,newdata=Hitters.test, n.trees=1000)
test_mse2 <- mean((yhat.boost-Salary.test)^2)
boost.Hitters<-gbm(Salary~., data=Hitters.train,n.trees=1000,interaction.depth=4,shrinkage=0.5)
yhat.boost<-predict(boost.Hitters,newdata=Hitters.test, n.trees=1000)
test_mse3 <- mean((yhat.boost-Salary.test)^2)
testm <- c(test_mse1, test_mse2, test_mse3)
testm
knitr::opts_chunk$set(echo = TRUE)
shrinkage <- c(0.001, 0.02, 0.5)
test_mse <- vector()
for (i in 1:3) {
boost.Hitters<-gbm(Salary~., data=Hitters,n.trees=1000,interaction.depth=4,shrinkage=shrinkage[i],verbose=F)
yhat.boost<-predict(boost.Hitters,newdata=Hitters.test, n.trees=1000)
test_mse <- c(test_mse,mean((yhat.boost-Hitters.test)^2))
}
knitr::opts_chunk$set(echo = TRUE)
# load library
library(tidyverse)
# load in large sample dataset
sample_data <- read_csv("ratings_1_sample.csv")
# Sample only 500 movies.
# extract movieID column
movieID <- as.vector(sample_data$MovieID)
# get only unique movie IDs
unique_movieID <- unique(movieID)
# sample 500 unique movie IDs
set.seed(1)
movieID_sample <- sample(unique_movieID,500, replace=F)
# new data frame, remove and store rows with movie ID in movieID_sample
sample_data2 <- sample_data[ sample_data$MovieID %in% movieID_sample, ]
# check number of unique movie IDs (should be 500)
unique_movieID2 <- unique(sample_data2$MovieID)
# Lastly, I'm going to drop the Date row for the time being.
ratings <- subset(sample_data2, select = c("X1","CustomerID","Rating","MovieID","MovieTitle"))
# Convert all 1 and 2 ratings to 0 and convert all 3, 4, and 5 ratings to 1.
# set minvalue
minval<-4
ratings$Rating[ratings$Rating<minval]=0
ratings$Rating[ratings$Rating>=minval]=1
train <- sample(dim(ratings)[1], dim(ratings)[1]/2)
ratings.train <- ratings[train,]
ratings.test <- ratings[-train,]
rating.test <- ratings$Rating[-train]
# get a feel for the data
summary(ratings)
pairs(subset(sample_data2, select = c("CustomerID","Rating","MovieID")))
cor(subset(sample_data2, select = c("CustomerID","Rating","MovieID")))
# generalized linear model on training data
glm.fit <- glm(Rating~MovieID,data=ratings.train,family=binomial)
glm.probs<-predict(glm.fit,newdata=ratings.test,type="response")
glm.pred<-rep(1,17857)
glm.pred[glm.probs>0.5]=1
mean(glm.pred == rating.test)
library(MASS)
lda.fit<-lda(Rating~MovieID,data=ratings,subset=train)
lda.pred<-predict(lda.fit,ratings.test)
mean(lda.pred$class != rating.test)
qda.fit<-qda(Rating~MovieID,data=ratings,subset=train)
qda.pred<-predict(qda.fit,ratings.test)
mean(qda.pred$class!=rating.test)
library(tree)
Rating1 <- ifelse(ratings$Rating==1,"Yes","No")
ratings<-data.frame(ratings,Rating1)
fit.tree<-tree(Rating1~MovieID,ratings[train,])
summary(fit.tree)
Rating1.test<-ratings$Rating1[-train]
tree.pred<-predict(fit.tree,ratings[-train,],type="class")
table(tree.pred,Rating1.test)
(5165+0)/17857
knitr::opts_chunk$set(echo = TRUE)
set.seed(1)
x-matrix(rnorm(20*2),ncol=2)
set.seed(1)
x=matrix(rnorm(20*2),ncol=2)
y=c(rep(-1,10),rep(1,10))
x[y==1,]=x[y==1,]+1
plot(x,col=(3-y))
dat=data.frame(x=x,y=as.factor(y)) # encode response as factor
library(e1071)
svmfit=svm(y~.,data=dat,kernel="linear",cost=10,scale=FALSE)
plot(svmfit,dat)
set.seed(1)
tune.out<-tune(svm,y~,data=dat,kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
set.seed(1)
tune.out<-tune(svm,y~.,data=dat,kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
bestmod <- tune.out$best.model
xtest<-matrix(rnorm(20*2),ncol=2)
ytest<-sample(c(-1,1),20,rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
testdat<-data.frame(x=xtest,y=as.factor(ytest))
ypred<-predict(bestmod,testdat)
table(predict=ypred,truth,testdat$y)
xtest<-matrix(rnorm(20*2),ncol=2)
ytest<-sample(c(-1,1),20,rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
testdat<-data.frame(x=xtest,y=as.factor(ytest))
ypred<-predict(bestmod,testdat)
table(predict=ypred,truth=testdat$y)
set.seed(1)
x<-matrix(rnorm(200*2),ncol=2)
x[1:100,]<-x[1:100,]+2
x[101:150,]=x[101:150,]-2
y<-c(rep(1,150),rep(2,50))
dat<-data.frame(x=x,y=as.factor(y))
plot(x,col=y)
dat<-data.frame(x=x,y=as.factor(y)) # encode response as factor
library(e1071)
svmfit<-svm(y~.,data=dat,kernel="linear",cost=10,scale=FALSE)
plot(svmfit,dat)
set.seed(1)
tune.out<-tune(svm,y~.,data=dat,kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
bestmod<-tune.out$best.model
xtest<-matrix(rnorm(20*2),ncol=2)
ytest<-sample(c(-1,1),20,rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
testdat<-data.frame(x=xtest,y=as.factor(ytest))
ypred<-predict(bestmod,testdat)
table(predict=ypred,truth=testdat$y)
train<-sample(200,100)
svmfit<-svm(y~.,data=dat[train,],kernel="radial",gamma=1,cost=1)
plot(svmfit,dat[train,])
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out)
table(true=dat[-train,"y"],pred=predict(tune.out$best.model,newx=dat[-train,]))
knitr::opts_chunk$set(echo = TRUE)
set.seed(1)
x<-matrix(rnorm(100*2),ncol=2)
x[1:50,]<-x[1:50,]+2
x[51:75,]=x[51:75,]-2
y<-c(rep(1,75),rep(2,25))
dat<-data.frame(x=x,y=as.factor(y))
plot(x,col=y)
dat<-data.frame(x=x,y=as.factor(y)) # encode response as factor
library(e1071)
svmfit<-svm(y~.,data=dat,kernel="linear",cost=10,scale=FALSE)
plot(svmfit,dat)
set.seed(1)
tune.out<-tune(svm,y~.,data=dat,kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
bestmod<-tune.out$best.model
xtest<-matrix(rnorm(200*2),ncol=2)
xtest[1:100,]<-x[1:100,]+2
xtest[101:150,]<-x[101:150,]-2
xtest<-matrix(rnorm(100*2),ncol=2)
xtest[1:50,]<-x[1:50,]+2
xtest[51:75,]<-x[51:75,]-2
ytest<-sample(c(1,75),10,rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,]+1
testdat<-data.frame(x=xtest,y=as.factor(ytest))
ypred<-predict(bestmod,testdat)
table(predict=ypred,truth=testdat$y)
train<-sample(200,100)
svmfit<-svm(y~.,data=dat[train,],kernel="radial",gamma=1,cost=1)
plot(svmfit,dat[train,])
train<-sample(200,100)
svmfit<-svm(y~.,data=dat[train,],kernel="radial",gamma=1,cost=1)
plot(svmfit,dat[train,])
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out)
table(true=dat[-train,"y"],pred=predict(tune.out$best.model,newx=dat[-train,]))
set . seed (1)
set.seed (1)
x=matrix(rnorm(20*2), ncol=2)
y=c(rep(-1,10), rep(1,10))
x[y==1,]=x[y==1,] + 1
dat<-data.frame(x=x,y=as.factor(y))
plot(x,col=y)
set.seed (1)
x=matrix(rnorm(20*2), ncol=2)
y=c(rep(-1,10), rep(1,10))
x[y==1,]=x[y==1,] + 1
dat<-data.frame(x=x,y=as.factor(y))
plot(x, col=(3-y))
set.seed (1)
x=matrix(rnorm(20*2), ncol=2)
y=c(rep(-1,10), rep(1,10))
x[y==1,]=x[y==1,] + 1
plot(x, col=(3-y))
dat<-data.frame(x=x,y=as.factor(y)) # encode response as factor
library(e1071)
svmfit<-svm(y~.,data=dat,kernel="linear",cost=10,scale=FALSE)
plot(svmfit,dat)
set.seed(1)
tune.out<-tune(svm,y~.,data=dat,kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
bestmod<-tune.out$best.model
xtest=matrix(rnorm(20*2), ncol=2)
ytest=sample(c(-1,1), 20, rep=TRUE)
xtest [ ytest ==1 ,]= xtest [ ytest ==1 ,] + 1
testdat=data.frame(x=xtest, y=as.factor(ytest))
ypred<-predict(bestmod,testdat)
table(predict=ypred,truth=testdat$y)
set.seed (1)
x=matrix(rnorm(100*2), ncol=2)
y=c(rep(-1,50), rep(1,50))
x[y==1,]=x[y==1,] + 1
plot(x, col=(3-y))
set.seed(1)
x<-matrix(rnorm(100*2), ncol=2)
x[1:50,]<-x[1:50,]+2
x[51:75,]<-x[51:75,]-2
y<-c(rep(1,75),rep(2,25))
dat<-data.frame(x=x,y=as.factor(y))
plot(x, col=y)
dat<-data.frame(x=x,y=as.factor(y)) # encode response as factor
library(e1071)
svmfit<-svm(y~.,data=dat,kernel="linear",cost=10,scale=FALSE)
plot(svmfit,dat)
set.seed(1)
tune.out<-tune(svm,y~.,data=dat,kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
bestmod<-tune.out$best.model
train<-sample(100, 50)
ypred<-predict(bestmod,dat[train,])
table(predict=ypred,truth=testdat$y)
train<-sample(100, 50)
ypred<-predict(bestmod,dat[-train,])
table(predict=ypred,truth=dat[-train,"y"])
train<-sample(200,100)
ypred<-predict(bestmod,dat[-train,])
table(predict=ypred,truth=dat[-train,"y"])
set.seed(1)
x<-matrix(rnorm(100*2), ncol=2)
x[1:50,]<-x[1:50,]+2
x[51:75,]<-x[51:75,]-2
y<-c(rep(1,75),rep(2,25))
dat<-data.frame(x=x,y=as.factor(y))
plot(x, col=y)
View(x)
set.seed(1)
x<-matrix(rnorm(100*2), ncol=2)
x[1:50,]<-x[1:50,]+2
x[51:75,]<-x[51:75,]-2
y<-c(rep(1,75),rep(2,25))
plot(x, col=y)
dat<-data.frame(x=x,y=as.factor(y)) # encode response as factor
train<-sample(200,100)
library(e1071)
svmfit<-svm(y~.,data=dat[train,],kernel="linear",cost=10,scale=FALSE)
plot(svmfit,dat)
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train],kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
bestmod<-tune.out$best.model
table(true=dat[-train,"y"],pred=predict(bestmod,newx=dat[-train,]))
svmfit<-svm(y~.,data=dat[train,],kernel="radial",gamma=1,cost=1)
plot(svmfit,dat[train,])
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out)
table(true=dat[-train,"y"],pred=predict(tune.out$best.model,newx=dat[-train,]))
set.seed(1)
x<-matrix(rnorm(100*2), ncol=2)
x[1:50,]<-x[1:50,]+2
x[51:75,]<-x[51:75,]-2
y<-c(rep(1,75),rep(2,25))
plot(x, col=y)
dat<-data.frame(x=x,y=as.factor(y)) # encode response as factor
train<-sample(100,75)
library(e1071)
svmfit<-svm(y~.,data=dat[train,],kernel="linear",cost=10,scale=FALSE)
plot(svmfit,dat)
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
bestmod<-tune.out$best.model
table(true=dat[-train,"y"],pred=predict(bestmod,newx=dat[-train,]))
set.seed(1)
x<-matrix(rnorm(200*2), ncol=2)
x[1:100,]<-x[1:100,]+2
x[101:150,]<-x[101:150]-2
y<-c(rep(150),rep(2,50))
plot(x, col=y)
dat<-data.frame(x=x,y=as.factor(y)) # encode response as factor
set.seed(1)
x<-matrix(rnorm(200*2), ncol=2)
x[1:100,]<-x[1:100,]+2
x[101:150,]<-x[101:150]-2
y<-c(rep(1,150),rep(2,50))
plot(x, col=y)
dat<-data.frame(x=x,y=as.factor(y)) # encode response as factor
train<-sample(200,100)
library(e1071)
svmfit<-svm(y~.,data=dat[train,],kernel="linear",cost=10,scale=FALSE)
plot(svmfit,dat)
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
bestmod<-tune.out$best.model
table(true=dat[-train,"y"],pred=predict(bestmod,newx=dat[-train,]))
svmfit<-svm(y~.,data=dat[train,],kernel="radial",gamma=1,cost=1)
plot(svmfit,dat[train,])
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out)
table(true=dat[-train,"y"],pred=predict(tune.out$best.model,newx=dat[-train,]))
set.seed(1)
x<-matrix(rnorm(200*2), ncol=2)
x[1:100,]<-x[1:100,]+2
x[101:150,]<-x[101:150]-2
y<-c(rep(1,150),rep(2,50))
plot(x, col=y)
dat<-data.frame(x=x,y=as.factor(y)) # encode response as factor
train<-sample(200,100)
library(e1071)
svmfit<-svm(y~.,data=dat[train,],kernel="linear",cost=10,scale=FALSE)
plot(svmfit,dat)
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
bestmod<-tune.out$best.model
table(true=dat[-train,"y"],pred=predict(bestmod,newx=dat[-train,]))
svmfit<-svm(y~.,data=dat[train,],kernel="radial",gamma=1,cost=1)
plot(svmfit,dat[train,])
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out)
table(true=dat[-train,"y"],pred=predict(tune.out$best.model,newx=dat[-train,]))
View(x)
set.seed(1)
x<-matrix(rnorm(100*2), ncol=2)
x[1:50,]<-x[1:50,]+2
x[51:75,]<-x[51:75]-2
y<-c(rep(1,75),rep(2,25))
plot(x, col=y)
dat<-data.frame(x=x,y=as.factor(y)) # encode response as factor
train<-sample(100,50)
View(x)
library(e1071)
svmfit<-svm(y~.,data=dat[train,],kernel="linear",cost=10,scale=FALSE)
plot(svmfit,dat)
set.seed(1)
tune.out<-tune(svmfit,y~.,data=dat[train,],kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
bestmod<-tune.out$best.model
table(true=dat[-train,"y"],pred=predict(bestmod,newx=dat[-train,]))
set.seed(1)
x<-matrix(rnorm(100*2), ncol=2)
x[1:50,]<-x[1:50,]+2
x[51:75,]<-x[51:75]-2
y<-c(rep(1,75),rep(2,25))
plot(x, col=y)
dat<-data.frame(x=x,y=as.factor(y)) # encode response as factor
train<-sample(100,50)
library(e1071)
svmfit<-svm(y~.,data=dat[train,],kernel="linear",cost=10,scale=FALSE)
plot(svmfit,dat)
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
bestmod<-tune.out$best.model
table(true=dat[-train,"y"],pred=predict(bestmod,newx=dat[-train,]))
svmfit<-svm(y~.,data=dat[train,],kernel="radial",gamma=1,cost=1)
plot(svmfit,dat[train,])
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out)
table(true=dat[-train,"y"],pred=predict(tune.out$best.model,newx=dat[-train,]))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
# load in large sample dataset
sample_data <- read_csv("ratings_1_sample.csv")
knitr::opts_chunk$set(echo = TRUE)
set.seed(1)
x<-matrix(rnorm(100*2), ncol=2)
x[1:50,]<-x[1:50,]+2
x[51:75,]<-x[51:75]-2
y<-c(rep(1,75),rep(2,25))
plot(x, col=y)
dat<-data.frame(x=x,y=as.factor(y)) # encode response as factor
train<-sample(100,50)
library(e1071)
svmfit<-svm(y~.,data=dat[train,],kernel="linear",cost=10,scale=FALSE)
plot(svmfit,dat)
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
bestmod<-tune.out$best.model
table(true=dat[-train,"y"],pred=predict(bestmod,newx=dat[-train,]))
svmfit<-svm(y~.,data=dat[train,],kernel="radial",gamma=1,cost=1)
plot(svmfit,dat[train,])
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out)
table(true=dat[-train,"y"],pred=predict(svmfit,newx=dat[-train,]))
svmfit<-svm(y~.,data=dat[train,],kernel="radial",gamma=1,cost=1)
plot(svmfit,dat[train,])
plot(svmfit,dat[-train,])
set.seed(10)
x<-matrix(rnorm(100*2), ncol=2)
x[1:50,]<-x[1:50,]+2
x[51:75,]<-x[51:75]-2
y<-c(rep(1,75),rep(2,25))
plot(x, col=y)
dat<-data.frame(x=x,y=as.factor(y)) # encode response as factor
train<-sample(100,50)
library(e1071)
svmfit<-svm(y~.,data=dat[train,],kernel="linear",cost=10,scale=FALSE)
plot(svmfit,dat)
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="linear",ranges=list(cost=c(0.001,0.01,0.1,1,5,10,100)))
bestmod<-tune.out$best.model
table(true=dat[-train,"y"],pred=predict(bestmod,newx=dat[-train,]))
svmfit<-svm(y~.,data=dat[train,],kernel="radial",gamma=1,cost=1)
plot(svmfit,dat[train,])
plot(svmfit,dat[-train,])
set.seed(1)
tune.out<-tune(svm,y~.,data=dat[train,],kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out)
table(true=dat[-train,"y"],pred=predict(svmfit,newx=dat[-train,]))
